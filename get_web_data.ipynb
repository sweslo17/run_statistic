{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import requests\n",
    "import datetime\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_df(url):\n",
    "    result = requests.get(url)\n",
    "    result.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(result.text)\n",
    "    data = []\n",
    "    for tr in soup.find_all('table')[1].find_all('tr'):\n",
    "        if tr.find_all('th'):\n",
    "            columns = [th.get_text().strip() for th in tr.find_all('th')]\n",
    "        if len(tr.find_all('td')) == 8 and not tr.find('table'):\n",
    "            data.append([td.get_text().strip() for td in tr.find_all('td')])\n",
    "    return data, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\user\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "#URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20161218&Race=MA&sn=136&pagenum={}\"\n",
    "\n",
    "#year = 2015\n",
    "#URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20151220&Race=MA&sn=111&pagenum={}\"\n",
    "#pages = 10\n",
    "\n",
    "#year = 2014\n",
    "#URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20141221&Race=MA&sn=86&pagenum={}\"\n",
    "#pages = 11\n",
    "\n",
    "#year = 2013\n",
    "#URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20131215&Race=MA&sn=57&pagenum={}\"\n",
    "#pages = 10\n",
    "\n",
    "#year = 2012\n",
    "#URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20121216&Race=MA&sn=32&pagenum={}\"\n",
    "#pages = 10\n",
    "\n",
    "year = 2011\n",
    "URL = \"https://www.run2pix.com/report/report_w.php?EventCode=20111218&Race=MA&sn=3&pagenum={}\"\n",
    "pages = 9\n",
    "\n",
    "for i in range(1,pages+1):\n",
    "    print(i)\n",
    "    result_data, columns = get_data_df(URL.format(i))\n",
    "    data += result_data\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_time(input_str):\n",
    "    seg = input_str.split(\":\")\n",
    "    hour = int(seg[0])\n",
    "    minute = int(seg[1])\n",
    "    second = int(seg[2])\n",
    "    if second >= 60:\n",
    "        minute += 1\n",
    "        second %= 60\n",
    "    if minute >= 60:\n",
    "        hour += 1\n",
    "        minute %= 60\n",
    "    return datetime.time(hour, minute, second)\n",
    "df['OfficialTime'] = df['OfficialTime'].apply(parse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['RankAll'] = df['RankAll'].apply(lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['seconds'] = df['OfficialTime'].apply(lambda x:x.hour*3600 + x.minute*60 + x.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
